{% set version = "1.0.1" %}

package:
  name: pytorch
  version: {{ version }}

source:
  # The tar source needs serious patching since it is trying to build
  # all 3rd party modules
  # url: https://github.com/pytorch/pytorch/archive/v{{ version }}.tar.gz
  # fn: pytorch-v{{ version }}.tar.gz
  # sha256: f360b7954e441bc5c4b36c49e711697a5c351de8b146c2982809385e3b3cfdcb
  git_url: https://github.com/pytorch/pytorch.git
  git_tag: v{{ version }}

# The build needs to set many environment variables
# This is an easy way to do it cross platform
{% set export = "export" %}  # [not win]
{% set export = "set" %}     # [win]

build:
  number: 0
  # Support for Windows and Python 2.7 is very experimental
  # https://ci.appveyor.com/project/conda-forge/staged-recipes/builds/21220961#L972
  skip: true  # [win and py27]
  # remove this when we settle on the actual organization
  skip: true  # [variant_str == 'cpu']
  skip: true  # [variant_str == 'gpu']
  script:
    # Most of this script is adapted from the pytorch/pythorch-cpu
    # meta.yaml.template build.sh and bld.bat scripts
    - {{ export }} TN_BINARY_BUILD=1
    - {{ export }} PYTORCH_BINARY_BUILD=1
    - {{ export }} NO_CUDA=1
    - {{ export }} PYTORCH_BUILD_VERSION={{ PKG_VERSION }}
    - {{ export }} PYTORCH_BUILD_NUMBER={{ PKG_BUILDNUM }}
    - {{ export }} BUILD_CUSTOM_PROTOBUF=ON
    - {{ export }} CMAKE_GENERATOR=Ninja
    # I have no idea what this flag does, but they recommend turning it on
    # when we don't find three of their headers.
    # It seemed to be required on Appveyor, but not azure, strange???
    # - {{ export }} GEN_TO_SOURCE=1                          # [win]
    # Why are all warnings treated as errors???
    - export CXXFLAGS="-Wno-error=unused-result $CXXFLAGS"  # [linux]
    - export CFLAGS="-Wno-error=unused-result $CFLAGS"      # [linux]
    # Disable this other 3rd party binary
    - {{ export }} NO_MKLDNN=1
    # - {{ export }} NO_TEST=1
    # I couldn't find any documentation on this, but eventually they call
    # a script tools/build_pytorch_libs.sh
    # whcih passes EXTRA_CAFFE2_CMAKE_FLAGS at the end of the cmake command
    # to all 3rd party libraries.
    - {{ export }} EXTRA_CAFFE2_CMAKE_FLAGS="-DUSE_MPI=OFF -DUSE_NUMA=OFF -DUSE_NCCL=OFF -DATEN_NO_TEST=OFF"
    # Why do I need to export these?
    #
    # The CMake for onnx reports:
    # therefore, it clearly has a bug somewhere
    # --   Protobuf compiler     : /home/mark2/miniconda3/envs/compile/bin/protoc
    # --   Protobuf includes     : /usr/include
    # --   Protobuf libraries    : /home/mark2/miniconda3/envs/compile/lib/libprotobuf.so;-lpthread
    - export CXXFLAGS="-I{{ PREFIX }}/include/ $CXXFLAGS"  # [unix]
    - export CFLAGS="-I{{ PREFIX }}/include/ $CFLAGS"  # [unix]
    # How do we add /std:c++11 to windows CFLAGS
    # There is an other weird python package called ninja
    # which is their preferred method of building
    # that said, it does nothing but call "ninja"
    # - pip install ninja
    # gpu version is just a stub
    - "{{ PYTHON }} -m pip install . --no-deps -vv --disable-pip-version-check"  # [variant_str == 'cpu']
requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake
    - ninja
    - make  # [unix]
  host:
    - python
    - pip
    - pyyaml
    - numpy 1.11
    - setuptools
    - cffi
    - typing  # [py <= 35]
    - ninja
    # 3rd party libraries that we are unbundling
    - pybind11
    # They seem to be pinned to something like protobuf 3.5
    # maybe we can remove this pin?
    # - protobuf  #  3.5
  run:
    - python
    - {{ pin_compatible('numpy') }}
    # ninja and cffi are included in
    - ninja
    - cffi
    - pytorch-cpu   # [variant_str == 'cpu']
    - pytorch-gpu   # [variant_str == 'gpu']

test:
  imports:
    - torch  # [variant_str == 'cpu']
    # Maybe we should have a test for a simple Neural Network???

outputs:
  - name: pytorch
  - name: pytorch-{{ variant_str }}
    requirements:
      run:
        - _pytorch_variant ==0={{ variant_str }}
    test:
      imports:
        # For now, gpu is only built using the pytorch channel
        - pytorch  # [variant == 'cpu']
    extra:
      pytorch_variant: {{ variant_str }}
  - name: _pytorch_variant
    version: {{ variant_version }}
    build:
      number: 0
      string: {{ variant_str }}

about:
  home: https://pytorch.org/
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."

extra:
  pytorch_variant: {{ variant_str }}
  recipe-maintainers:
    - hmaarrfk
    - sodre
