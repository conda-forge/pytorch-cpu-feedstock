{% set version = "2.5.1" %}
{% set build = 7 %}

{% if cuda_compiler_version != "None" %}
{% set build = build + 200 %}
{% endif %}

{% if blas_impl == "mkl" %}
{% set build = build + 100 %}
{% endif %}

{% set mkl = "<2024" %}

# a reasonably safe subset of tests that should run under 15 minutes
# disable hypothesis because it randomly yields health check errors
{% set tests = " ".join([
    "test/test_autograd.py",
    "test/test_autograd_fallback.py",
    "test/test_custom_ops.py",
    "test/test_linalg.py",
    "test/test_mkldnn.py",
    "test/test_modules.py",
    "test/test_nn.py",
    "test/test_torch.py",
    "test/test_xnnpack_integration.py",
    "--deselect test/test_torch.py::TestTorch::test_print",
    "-m 'not hypothesis'",
]) %}
{% set tests_3_13_deselects = " ".join([
    "--deselect test/test_custom_ops.py::TestCustomOp::test_data_dependent_compile",
    "--deselect test/test_custom_ops.py::TestCustomOp::test_functionalize_error",
    "--deselect test/test_custom_ops.py::TestCustomOpAPI::test_compile",
    "--deselect test/test_custom_ops.py::TestCustomOpAPI::test_fake",
    "-k 'not test_compile_int4_mm and not test_compile_int8_mm'",
]) %}

package:
  name: libtorch-split
  version: {{ version }}

source:
  url: https://github.com/pytorch/pytorch/releases/download/v{{ version }}/pytorch-v{{ version }}.tar.gz
  sha256: 740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266
  patches:
    - patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch
    # https://github.com/pytorch/pytorch/pull/137084
    - patches/0002-Help-find-numpy.patch
    # https://github.com/pytorch/pytorch/pull/138287
    - patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch
    # sympy 1.13.2 was reported to result in test failures on Windows and mac
    # https://github.com/pytorch/pytorch/pull/133235
    - patches/0004-Update-sympy-version.patch
    - patches/0005-Fix-duplicate-linker-script.patch  # [cuda_compiler_version != "None" and aarch64]
    # https://github.com/pytorch/pytorch/pull/136034
    - patches/0006-3.13-fix-3.13-pickle-error-in-serialization.py-13603.patch
    # https://github.com/pytorch/pytorch/pull/137331
    - patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch
    # conda-specific patch, upstream force-disables libcufile w/ TH_BINARY_BUILD
    # for their PyPI wheel builds
    - patches/0008-Allow-libcufile-for-conda-builds.patch
    # conda-specific patch, lets us override CUDA paths
    - patches/0009-Allow-overriding-CUDA-related-paths.patch
    # NumPy 2 fixes:
    # https://github.com/pytorch/pytorch/pull/136800
    - patches/0010-Fix-test-test_linalg.py-for-NumPy-2-136800.patch
    # https://github.com/pytorch/pytorch/pull/137740
    - patches/0011-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch
    # conda-specific patch for libtorch_cuda_linalg split
    - patches/0012-Adjust-CUDAHooks-hasMAGMA-for-libtorch_cuda_linalg.s.patch

build:
  number: {{ build }}
  skip: true  # [win]
  # cuda 11.8 was dropped due to maintenance effort, see discussion in #177
  skip: true  # [cuda_compiler_version == "11.8"]

requirements:
  # Keep this list synchronized (except for python*, numpy*) in outputs
  # We use python to build libtorch as well because it is easier
  build:
    # When you change 3.12 here, change it in build.sh as well
    - python 3.12                            # [megabuild and build_platform != target_platform]
    - python                                 # [not megabuild and build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - numpy  *                               # [megabuild and build_platform != target_platform]
    - numpy                                  # [not megabuild and build_platform != target_platform]
    - {{ stdlib('c') }}
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                 # [cuda_compiler_version != "None"]
    # Dec 2020: it seems that git is broken on windows, so we use m2-git
    - m2-patch  # [win]
    - m2-git    # [win]
    - patch     # [not win]
    - git       # [not win]
    - libgomp        # [linux]
    - llvm-openmp    # [osx]
    - cmake
    - ninja
    # Keep libprotobuf here so that a compatibile version
    # of protobuf is installed between build and host
    - libprotobuf
    - protobuf
    - make      # [linux]
  host:
    # GPU requirements
    - cudnn                           # [cuda_compiler_version != "None"]
    - nccl                            # [cuda_compiler_version != "None"]
    - magma                           # [cuda_compiler_version != "None"]
    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
    - nvtx-c                          # [cuda_compiler_version != "None"]
    {% if cuda_compiler_version != "None" %}
    - cuda-driver-dev
    - cuda-cudart-dev
    - cuda-nvrtc-dev
    - cuda-nvtx-dev
    - cuda-nvml-dev
    - cuda-profiler-api
    - libcublas-dev
    - libcufile-dev
    - libcufft-dev
    - libcurand-dev
    - libcusolver-dev
    - libcusparse-dev
    {% endif %}
    # other requirements
    - python 3.12  # [megabuild]
    - python       # [not megabuild]
    - wheel
    - numpy *      # [megabuild]
    - numpy        # [not megabuild]
    - pip
    - setuptools
    - pyyaml
    - requests
    - six
    - mkl-devel {{ mkl }}   # [blas_impl == "mkl"]
    - libcblas * *_mkl      # [blas_impl == "mkl"]
    - libcblas              # [blas_impl != "mkl"]
    - liblapack             # [blas_impl != "mkl"]
    - libgomp   # [linux]
    - llvm-openmp    # [osx]
    - libabseil
    - libprotobuf
    - sleef
    - libuv
    - pkg-config  # [unix]
    - typing_extensions

outputs:
  - name: libtorch-cuda-linalg
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}_magma_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}    # [use_magma]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}_nomagma_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [not use_magma]
      skip: true  # [win or cuda_compiler_version == "None"]
      ignore_run_exports_from:
        - python *                               # [megabuild]
        - numpy *                                # [megabuild]
        - cross-python_{{ target_platform }}     # [megabuild and build_platform != target_platform]
      ignore_run_exports:
        - python *                               # [megabuild]
        - numpy *                                # [megabuild]
      track_features:
        - nomagma                                # [not use_magma]
    script: build_common.sh     # [unix]
    script: build_common.bat    # [win]
    requirements:
      build:
        # When you change 3.12 here, change it in build.sh as well
        - python 3.12                            # [megabuild and build_platform != target_platform]
        - python                                 # [not megabuild and build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - numpy  *                               # [megabuild and build_platform != target_platform]
        - numpy                                  # [not megabuild and build_platform != target_platform]
        - {{ stdlib('c') }}
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}
        - patch
        - git
        - libgomp
        - cmake
        - ninja
        # Keep libprotobuf here so that a compatibile version
        # of protobuf is installed between build and host
        - libprotobuf
        - protobuf
        - make
      host:
        # GPU requirements
        - cudnn
        - nccl
        - cuda-version {{ cuda_compiler_version }}
        - nvtx-c
        - cuda-driver-dev
        - cuda-cudart-dev
        - cuda-nvrtc-dev
        - cuda-nvtx-dev
        - cuda-nvml-dev
        - cuda-profiler-api
        - libcublas-dev
        - libcufile-dev
        - libcufft-dev
        - libcurand-dev
        - libcusolver-dev
        - libcusparse-dev
        - magma        # [use_magma]
        # other requirements
        - python 3.12  # [megabuild]
        - python       # [not megabuild]
        - numpy *      # [megabuild]
        - numpy        # [not megabuild]
        - pip
        - setuptools
        - pyyaml
        - requests
        - six
        - mkl-devel {{ mkl }}   # [blas_impl == "mkl"]
        - libcblas * *_mkl      # [blas_impl == "mkl"]
        - libcblas              # [blas_impl != "mkl"]
        - liblapack             # [blas_impl != "mkl"]
        - libgomp
        - libabseil
        - libprotobuf
        - sleef
        - libuv
        - pkg-config
        - typing_extensions
      run:
        # GPU requirements without run_exports
        - {{ pin_compatible('cudnn') }}
      run_constrained:
        - libmagma <0.0a0  # [not use_magma]
    test:
      commands:
        - test -f $PREFIX/lib/libtorch_cuda_linalg.so

  - name: libtorch
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                 # [cuda_compiler_version == "None"]
      detect_binary_files_with_prefix: false
      run_exports:
        - {{ pin_subpackage('libtorch', max_pin='x.x') }}
      ignore_run_exports_from:
        - magma *
        - python *                               # [megabuild]
        - numpy *                                # [megabuild]
        - cross-python_{{ target_platform }}     # [megabuild and build_platform != target_platform]
      ignore_run_exports:
        - python *                               # [megabuild]
        - numpy *                                # [megabuild]
    script: build.sh   # [unix]
    script: bld.bat    # [win]
    requirements:
      build:
        # When you change 3.12 here, change it in build.sh as well
        - python 3.12                            # [megabuild and build_platform != target_platform]
        - python                                 # [not megabuild and build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - numpy  *                               # [megabuild and build_platform != target_platform]
        - numpy                                  # [not megabuild and build_platform != target_platform]
        - {{ stdlib('c') }}
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}                 # [cuda_compiler_version != "None"]
        # Dec 2020: it seems that git is broken on windows, so we use m2-git
        - m2-patch  # [win]
        - m2-git    # [win]
        - patch     # [not win]
        - git       # [not win]
        - libgomp        # [linux]
        - llvm-openmp    # [osx]
        - cmake
        - ninja
        # Keep libprotobuf here so that a compatibile version
        # of protobuf is installed between build and host
        - libprotobuf
        - protobuf
        - make      # [linux]
      host:
        # GPU requirements
        - cudnn                           # [cuda_compiler_version != "None"]
        - nccl                            # [cuda_compiler_version != "None"]
        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
        - nvtx-c                          # [cuda_compiler_version != "None"]
        {% if cuda_compiler_version != "None" %}
        - cuda-driver-dev
        - cuda-cudart-dev
        - cuda-nvrtc-dev
        - cuda-nvtx-dev
        - cuda-nvml-dev
        - cuda-profiler-api
        - libcublas-dev
        - libcufile-dev
        - libcufft-dev
        - libcurand-dev
        - libcusolver-dev
        - libcusparse-dev
        {% endif %}
        # other requirements
        - python 3.12  # [megabuild]
        - python       # [not megabuild]
        - numpy *      # [megabuild]
        - numpy        # [not megabuild]
        - pip
        - setuptools
        - pyyaml
        - requests
        - six
        - mkl-devel {{ mkl }}   # [blas_impl == "mkl"]
        - libcblas * *_mkl      # [blas_impl == "mkl"]
        - libcblas              # [blas_impl != "mkl"]
        - liblapack             # [blas_impl != "mkl"]
        - libgomp   # [linux]
        - llvm-openmp    # [osx]
        - libabseil
        - libprotobuf
        - sleef
        - libuv
        - pkg-config  # [unix]
        - typing_extensions
        - libtorch-cuda-linalg {{ version }}                  # [cuda_compiler_version != "None"]
      run:
        - libtorch-cuda-linalg {{ version }}                  # [cuda_compiler_version != "None"]
        # GPU requirements without run_exports
        - {{ pin_compatible('cudnn') }}                       # [cuda_compiler_version != "None"]
      run_constrained:
        # These constraints ensure conflict between pytorch and
        # pytorch-cpu 1.1 which we built before conda-forge had GPU infrastructure
        # built into place.
        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/65
        - pytorch-cpu =={{ version }}  # [cuda_compiler_version == "None"]
        - pytorch-gpu ==99999999       # [cuda_compiler_version == "None"]
        - pytorch-gpu =={{ version }}  # [cuda_compiler_version != "None"]
        - pytorch-cpu ==99999999       # [cuda_compiler_version != "None"]
        - pytorch {{ version }} cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_*_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
        - pytorch {{ version }} cpu_{{ blas_impl }}_*_{{ PKG_BUILDNUM }}                                                 # [cuda_compiler_version == "None"]
    test:
      commands:
        # libraries
        {% for each_lib in [ 'libc10', 'libshm', 'libtorch', 'libtorch_cpu', 'libtorch_global_deps'] %}
        - test -f $PREFIX/lib/{{ each_lib }}.so     # [linux]
        - test -f $PREFIX/lib/{{ each_lib }}.dylib  # [osx]
        {% endfor %}
        {% for each_lib in ['libc10_cuda', 'libcaffe2_nvrtc', 'libtorch_cuda'] %}
        - test -f $PREFIX/lib/{{ each_lib }}.so     # [linux and cuda_compiler_version != "None"]
        {% endfor %}

  - name: pytorch
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                 # [cuda_compiler_version == "None"]
      detect_binary_files_with_prefix: false
      ignore_run_exports_from:
        - magma
      run_exports:
        - {{ pin_subpackage('pytorch', max_pin='x.x') }}
        - {{ pin_subpackage('libtorch', max_pin='x.x') }}

    script: build_pytorch.sh   # [unix]
    script: build_pytorch.bat  # [win]
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - numpy                                  # [build_platform != target_platform]
        - {{ stdlib('c') }}
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}                 # [cuda_compiler_version != "None"]
        # Dec 2020: it seems that git is broken on windows, so we use m2-git
        - patch     # [not win]
        - m2-patch  # [win]
        - git       # [not win]
        - m2-git    # [win]
        - libgomp   # [linux]
        - llvm-openmp    # [osx]
        - cmake
        - ninja
        # Keep libprotobuf here so that a compatibile version
        # of protobuf is installed between build and host
        - libprotobuf
        - protobuf
        - make      # [linux]
      host:
        # GPU requirements
        - cudnn                           # [cuda_compiler_version != "None"]
        - nccl                            # [cuda_compiler_version != "None"]
        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
        - nvtx-c                          # [cuda_compiler_version != "None"]
        - magma                           # [cuda_compiler_version != "None"]
        {% if cuda_compiler_version != "None" %}
        - cuda-driver-dev
        - cuda-cudart-dev
        - cuda-nvrtc-dev
        - cuda-nvtx-dev
        - cuda-nvml-dev
        - cuda-profiler-api
        - libcublas-dev
        - libcufile-dev
        - libcufft-dev
        - libcurand-dev
        - libcusolver-dev
        - libcusparse-dev
        {% endif %}
        # other requirements
        - python
        - numpy
        - pip
        - setuptools
        - pyyaml
        - requests
        - six
        - mkl-devel {{ mkl }}   # [blas_impl == "mkl"]
        - libcblas * *_mkl      # [blas_impl == "mkl"]
        - libcblas              # [blas_impl != "mkl"]
        - liblapack             # [blas_impl != "mkl"]
        - libgomp   # [linux]
        - llvm-openmp    # [osx]
        - libabseil
        - libprotobuf
        - sleef
        - libuv
        - pkg-config  # [unix]
        - typing_extensions
        - {{ pin_subpackage('libtorch', exact=True) }}
      run:
        - llvm-openmp    # [osx]
        # GPU requirements without run_exports
        - {{ pin_compatible('cudnn') }}                       # [cuda_compiler_version != "None"]
        # other requirements
        - python
        - typing_extensions
        # sympy 1.13.2 was reported to result in test failures on Windows and mac
        # https://github.com/pytorch/pytorch/pull/133235
        - sympy >=1.13.1,!=1.13.2
        - filelock
        - jinja2
        - networkx
        - nomkl                 # [blas_impl != "mkl"]
        - fsspec
        # avoid that people without GPUs needlessly download ~0.5-1GB
        - __cuda  # [cuda_compiler_version != "None"]
        - libtorch {{ version }}
        - setuptools
      run_constrained:
        # These constraints ensure conflict between pytorch and
        # pytorch-cpu 1.1 which we built before conda-forge had GPU infrastructure
        # built into place.
        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/65
        - pytorch-cpu =={{ version }}  # [cuda_compiler_version == "None"]
        - pytorch-gpu ==99999999       # [cuda_compiler_version == "None"]
        - pytorch-gpu =={{ version }}  # [cuda_compiler_version != "None"]
        - pytorch-cpu ==99999999       # [cuda_compiler_version != "None"]

    test:
      requires:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - ninja
        - boto3
        - hypothesis
        - pytest
        - tabulate
        - pydot
        - pip
        - expecttest
        - xmlrunner
        - pytest-flakefinder
        - pytest-rerunfailures
        - pytest-xdist
      imports:
        - torch  # [cuda_compiler_version == "None"]
      source_files:
        - test
        # tools/ is needed to optimise test run
        # as of pytorch=2.0.0, there is a bug when trying to run tests without the tools
        - tools
      commands:
        # the whole test suite takes forever, but we should get a good enough coverage
        # for potential packaging problems by running a fixed subset
        - OMP_NUM_THREADS=4 python -m pytest -n auto {{ tests }}    # [not win and cuda_compiler_version == "None" and py != 313]
        - python -m pytest -n auto {{ tests }}                      # [win and py != 313]
        # dynamo does not support python 3.13
        - OMP_NUM_THREADS=4 python -m pytest -n auto {{ tests_3_13_deselects }} {{ tests }}  # [not win and cuda_compiler_version == "None" and py == 313]
        - python -m pytest -n auto {{ tests_3_13_deselects }} {{ tests }}                    # [win and py == 313]
        # Run pip check so as to ensure that all pytorch packages are installed
        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/24
        - pip check
        - python -c "import torch; print(torch.__version__)"                       # [cuda_compiler_version == "None"]
        - python -c "import torch; assert torch.backends.mkldnn.m.is_available()"  # [x86 and cuda_compiler_version == "None"]
        - python -c "import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')"
        # At conda-forge, we target versions of OSX that are too old for MPS support
        # But if users install a newer version of OSX, they will have MPS support
        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/123#issuecomment-1186355073
        # - python -c "import torch; assert torch.backends.mps.is_available()" # [osx]
        - test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}     # [unix]

  # 2021/08/01, hmaarrfk
  # While this seems like a roundabout way of defining the package name
  # It helps the linter avoid errors on a package not having tests.
  {% set pytorch_cpu_gpu = "pytorch-cpu" %}   # [cuda_compiler_version == "None"]
  {% set pytorch_cpu_gpu = "pytorch-gpu" %}   # [cuda_compiler_version != "None"]
  - name: {{ pytorch_cpu_gpu }}
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                  # [megabuild and cuda_compiler_version != "None"]
      string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                                # [megabuild and cuda_compiler_version == "None"]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [not megabuild and cuda_compiler_version != "None"]
      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [not megabuild and cuda_compiler_version == "None"]
      detect_binary_files_with_prefix: false
      # weigh down cpu implementation and give cuda preference
      track_features:
        - pytorch-cpu                                      # [cuda_compiler_version == "None"]
    requirements:
      run:
        - pytorch {{ version }}=cuda_{{ blas_impl }}*{{ PKG_BUILDNUM }}   # [megabuild and cuda_compiler_version != "None"]
        - pytorch {{ version }}=cpu_{{ blas_impl }}*{{ PKG_BUILDNUM }}    # [megabuild and cuda_compiler_version == "None"]
        - {{ pin_subpackage("pytorch", exact=True) }}                     # [not megabuild]
    test:
      imports:
        - torch

about:
  home: https://pytorch.org/
  dev_url: https://github.com/pytorch/pytorch
  license: BSD-3-Clause
  license_family: BSD
  license_file:
    - LICENSE
    - NOTICE
    - third_party/pybind11/LICENSE
  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.

extra:
  recipe-maintainers:
    - jeongseok-meta
    - hmaarrfk
    - sodre
    - benjaminrwilson
    - Tobias-Fischer
    - beckermr
  feedstock-name: pytorch-cpu
