From 17865a4af5ca2e97a168b61f881a11cb16780230 Mon Sep 17 00:00:00 2001
From: cyy <cyyever@outlook.com>
Date: Mon, 16 Dec 2024 00:59:26 +0000
Subject: [PATCH] Hide torch_python symbols (#142214)

Change symbols in torch_python to invisible by default on platforms other than Apple.
Pull Request resolved: https://github.com/pytorch/pytorch/pull/142214
Approved by: https://github.com/ezyang
---
 torch/CMakeLists.txt                         | 2 +-
 torch/csrc/Layout.h                          | 4 ++--
 torch/csrc/MemoryFormat.h                    | 3 ++-
 torch/csrc/Module.cpp                        | 3 ++-
 torch/csrc/QScheme.h                         | 3 ++-
 torch/csrc/Size.h                            | 3 ++-
 torch/csrc/Storage.h                         | 4 ++--
 torch/csrc/TypeInfo.h                        | 5 +++--
 torch/csrc/autograd/python_function.h        | 7 ++++---
 torch/csrc/lazy/ts_backend/ts_backend_impl.h | 2 +-
 torch/csrc/tensor/python_tensor.h            | 7 ++++---
 torch/csrc/utils/device_lazy_init.h          | 3 ++-
 12 files changed, 27 insertions(+), 19 deletions(-)

diff --git a/torch/csrc/Layout.h b/torch/csrc/Layout.h
index 3b6844c9bad..a6864094df9 100644
--- a/torch/csrc/Layout.h
+++ b/torch/csrc/Layout.h
@@ -1,5 +1,5 @@
 #pragma once
-
+#include <torch/csrc/Export.h>
 #include <torch/csrc/python_headers.h>
 
 #include <ATen/Layout.h>
@@ -15,7 +15,7 @@ struct THPLayout {
   char name[LAYOUT_NAME_LEN + 1];
 };
 
-extern PyTypeObject THPLayoutType;
+TORCH_PYTHON_API extern PyTypeObject THPLayoutType;
 
 inline bool THPLayout_Check(PyObject* obj) {
   return Py_TYPE(obj) == &THPLayoutType;
diff --git a/torch/csrc/MemoryFormat.h b/torch/csrc/MemoryFormat.h
index 566270e70ab..c539564b1b8 100644
--- a/torch/csrc/MemoryFormat.h
+++ b/torch/csrc/MemoryFormat.h
@@ -1,5 +1,6 @@
 #pragma once
 
+#include <torch/csrc/Export.h>
 #include <torch/csrc/python_headers.h>
 
 #include <c10/core/MemoryFormat.h>
@@ -15,7 +16,7 @@ struct THPMemoryFormat {
   char name[MEMORY_FORMAT_NAME_LEN + 1];
 };
 
-extern PyTypeObject THPMemoryFormatType;
+TORCH_PYTHON_API extern PyTypeObject THPMemoryFormatType;
 
 inline bool THPMemoryFormat_Check(PyObject* obj) {
   return Py_TYPE(obj) == &THPMemoryFormatType;
diff --git a/torch/csrc/Module.cpp b/torch/csrc/Module.cpp
index 2182cd84cf1..4b083fb7bde 100644
--- a/torch/csrc/Module.cpp
+++ b/torch/csrc/Module.cpp
@@ -46,6 +46,7 @@
 #include <torch/csrc/Dtype.h>
 #include <torch/csrc/DynamicTypes.h>
 #include <torch/csrc/Event.h>
+#include <torch/csrc/Export.h>
 #include <torch/csrc/Generator.h>
 #include <torch/csrc/Layout.h>
 #include <torch/csrc/MemoryFormat.h>
@@ -1717,7 +1718,7 @@ class WeakTensorRef {
   }
 };
 
-extern "C" C10_EXPORT PyObject* initModule();
+extern "C" TORCH_PYTHON_API PyObject* initModule();
 // separate decl and defn for msvc error C2491
 PyObject* initModule() {
   HANDLE_TH_ERRORS
diff --git a/torch/csrc/QScheme.h b/torch/csrc/QScheme.h
index f604772fb82..af8f6452032 100644
--- a/torch/csrc/QScheme.h
+++ b/torch/csrc/QScheme.h
@@ -1,5 +1,6 @@
 #pragma once
 
+#include <torch/csrc/Export.h>
 #include <torch/csrc/python_headers.h>
 
 #include <c10/core/QScheme.h>
@@ -15,7 +16,7 @@ struct THPQScheme {
   char name[QSCHEME_NAME_LEN + 1];
 };
 
-extern PyTypeObject THPQSchemeType;
+TORCH_PYTHON_API extern PyTypeObject THPQSchemeType;
 
 inline bool THPQScheme_Check(PyObject* obj) {
   return Py_TYPE(obj) == &THPQSchemeType;
diff --git a/torch/csrc/Size.h b/torch/csrc/Size.h
index dd4283f7d77..1f4ec4dace3 100644
--- a/torch/csrc/Size.h
+++ b/torch/csrc/Size.h
@@ -1,10 +1,11 @@
 #pragma once
 
+#include <torch/csrc/Export.h>
 #include <torch/csrc/autograd/variable.h>
 #include <torch/csrc/python_headers.h>
 #include <cstdint>
 
-extern PyTypeObject THPSizeType;
+TORCH_PYTHON_API extern PyTypeObject THPSizeType;
 
 #define THPSize_Check(obj) (Py_TYPE(obj) == &THPSizeType)
 
diff --git a/torch/csrc/Storage.h b/torch/csrc/Storage.h
index fc63d14ab93..36314171fac 100644
--- a/torch/csrc/Storage.h
+++ b/torch/csrc/Storage.h
@@ -21,7 +21,7 @@ TORCH_PYTHON_API PyObject* THPStorage_NewWithStorage(
     c10::Storage _storage,
     c10::impl::PyInterpreterStatus status,
     bool allow_preexisting_pyobj = false);
-extern PyTypeObject* THPStorageClass;
+TORCH_PYTHON_API extern PyTypeObject* THPStorageClass;
 
 inline bool THPStorage_CheckTypeExact(PyTypeObject* tp) {
   return tp == THPStorageClass;
@@ -47,7 +47,7 @@ void THPStorage_postInit(PyObject* module);
 void THPStorage_assertNotNull(THPStorage* storage);
 void THPStorage_assertNotNull(PyObject* obj);
 
-extern PyTypeObject THPStorageType;
+TORCH_PYTHON_API extern PyTypeObject THPStorageType;
 
 inline const c10::Storage& THPStorage_Unpack(THPStorage* storage) {
   return *storage->cdata;
diff --git a/torch/csrc/TypeInfo.h b/torch/csrc/TypeInfo.h
index 6841312e4a9..9eb03a49093 100644
--- a/torch/csrc/TypeInfo.h
+++ b/torch/csrc/TypeInfo.h
@@ -1,5 +1,6 @@
 #pragma once
 
+#include <torch/csrc/Export.h>
 #include <torch/csrc/python_headers.h>
 
 #include <ATen/ATen.h>
@@ -13,8 +14,8 @@ struct THPFInfo : THPDTypeInfo {};
 
 struct THPIInfo : THPDTypeInfo {};
 
-extern PyTypeObject THPFInfoType;
-extern PyTypeObject THPIInfoType;
+TORCH_PYTHON_API extern PyTypeObject THPFInfoType;
+TORCH_PYTHON_API extern PyTypeObject THPIInfoType;
 
 inline bool THPFInfo_Check(PyObject* obj) {
   return Py_TYPE(obj) == &THPFInfoType;
diff --git a/torch/csrc/autograd/python_function.h b/torch/csrc/autograd/python_function.h
index 8c4f2f68dc5..5763d5a8339 100644
--- a/torch/csrc/autograd/python_function.h
+++ b/torch/csrc/autograd/python_function.h
@@ -3,6 +3,7 @@
 #include <torch/csrc/python_headers.h>
 
 #include <torch/csrc/Exceptions.h>
+#include <torch/csrc/Export.h>
 #include <torch/csrc/autograd/custom_function.h>
 #include <torch/csrc/autograd/function.h>
 #include <torch/csrc/autograd/saved_variable.h>
@@ -150,9 +151,9 @@ struct THPFunction {
 };
 
 bool THPFunction_initModule(PyObject* module);
-extern PyTypeObject THPFunctionType;
-extern PyObject* THPFunctionClass;
-extern PyObject* THPGradientEdgeClass;
+TORCH_PYTHON_API extern PyTypeObject THPFunctionType;
+TORCH_PYTHON_API extern PyObject* THPFunctionClass;
+TORCH_PYTHON_API extern PyObject* THPGradientEdgeClass;
 
 inline bool THPFunction_Check(PyObject* obj) {
   return PyObject_IsInstance(obj, (PyObject*)&THPFunctionType);
diff --git a/torch/csrc/lazy/ts_backend/ts_backend_impl.h b/torch/csrc/lazy/ts_backend/ts_backend_impl.h
index 701176c0790..a44334c54f8 100644
--- a/torch/csrc/lazy/ts_backend/ts_backend_impl.h
+++ b/torch/csrc/lazy/ts_backend/ts_backend_impl.h
@@ -47,6 +47,6 @@ class TORCH_API TSData : public torch::lazy::BackendData {
 
 TORCH_API torch::lazy::BackendImplInterface* GetTSBackendImpl();
 
-TORCH_API void InitTorchScriptBackend();
+TORCH_PYTHON_API void InitTorchScriptBackend();
 
 } // namespace torch::lazy
diff --git a/torch/csrc/tensor/python_tensor.h b/torch/csrc/tensor/python_tensor.h
index f69ded46a04..6c2d19a2397 100644
--- a/torch/csrc/tensor/python_tensor.h
+++ b/torch/csrc/tensor/python_tensor.h
@@ -3,6 +3,7 @@
 #include <c10/core/Device.h>
 #include <c10/core/DispatchKey.h>
 #include <c10/core/ScalarType.h>
+#include <torch/csrc/Export.h>
 #include <torch/csrc/python_headers.h>
 
 namespace at {
@@ -13,13 +14,13 @@ namespace torch::tensors {
 
 // Initializes the Python tensor type objects: torch.FloatTensor,
 // torch.DoubleTensor, etc. and binds them in their containing modules.
-void initialize_python_bindings();
+TORCH_PYTHON_API void initialize_python_bindings();
 
 // Same as set_default_tensor_type() but takes a PyObject*
-void py_set_default_tensor_type(PyObject* type_obj);
+TORCH_PYTHON_API void py_set_default_tensor_type(PyObject* type_obj);
 
 // Same as py_set_default_tensor_type, but only changes the dtype (ScalarType).
-void py_set_default_dtype(PyObject* dtype_obj);
+TORCH_PYTHON_API void py_set_default_dtype(PyObject* dtype_obj);
 
 // Gets the DispatchKey for the default tensor type.
 //
diff --git a/torch/csrc/utils/device_lazy_init.h b/torch/csrc/utils/device_lazy_init.h
index bc5f4912e2a..16fbe41bb83 100644
--- a/torch/csrc/utils/device_lazy_init.h
+++ b/torch/csrc/utils/device_lazy_init.h
@@ -1,6 +1,7 @@
 #pragma once
 
 #include <c10/core/TensorOptions.h>
+#include <torch/csrc/Export.h>
 
 // device_lazy_init() is always compiled, even for CPU-only builds.
 
@@ -23,7 +24,7 @@ namespace torch::utils {
  * try to use CUDA or XPU functionality from a CPU-only build, which is not good
  * UX.
  */
-void device_lazy_init(at::DeviceType device_type);
+TORCH_PYTHON_API void device_lazy_init(at::DeviceType device_type);
 void set_requires_device_init(at::DeviceType device_type, bool value);
 
 inline void maybe_initialize_device(at::Device& device) {
-- 
2.20.1.windows.1

